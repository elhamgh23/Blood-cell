{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9yXiCjkzkvd"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from skimage import io, color, exposure, filters,segmentation\n",
        "import numpy as np\n",
        "from scipy.ndimage import morphology,measurements,sum\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import PIL\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.morphology import disk\n",
        "from skimage import measure\n",
        "import skimage.morphology\n",
        "import os\n",
        "# importing libraries\n",
        "import tensorflow\n",
        "import keras\n",
        "import glob\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def otsu_thresholding(image):\n",
        "   M, N = image.shape  # Image dimensions\n",
        "\n",
        "   # Calculate probabilities for each intensity level using histogram\n",
        "   histogram, bins = np.histogram(image.flatten(), bins=256, range=(0, 256))\n",
        "   probabilities = histogram / (M * N)\n",
        "\n",
        "   # Initialize variables\n",
        "   output_class_probabilities = [0, 0]  # Probabilities of classes\n",
        "   output_class_means = [0, 0]  # Means of classes\n",
        "   threshold_range = range(256)\n",
        "   between_class_variance = 0\n",
        "\n",
        "   # Iterate through all possible thresholds\n",
        "   for t in threshold_range:\n",
        "       # Calculate weights and means of classes for threshold t\n",
        "       weight1 = np.sum(probabilities[:t])\n",
        "       weight2 = np.sum(probabilities[t:])\n",
        "       mean1 = np.sum(np.arange(t) * probabilities[:t]) / weight1 if weight1 > 0 else 0\n",
        "       mean2 = np.sum(np.arange(t, 256) * probabilities[t:]) / weight2 if weight2 > 0 else 0\n",
        "\n",
        "       # Calculate within-class variance for threshold t\n",
        "       within_class_variance = weight1 * (mean1 - np.mean(image))**2 + weight2 * (mean2 - np.mean(image))**2\n",
        "\n",
        "       # Update best threshold and between-class variance\n",
        "       if between_class_variance < within_class_variance:\n",
        "           between_class_variance = within_class_variance\n",
        "           best_threshold = t\n",
        "\n",
        "   # Apply thresholding\n",
        "   thresholded_image = np.where(image < best_threshold, 0, 1)\n",
        "\n",
        "   return thresholded_image"
      ],
      "metadata": {
        "id": "hMZ4-aes08O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_morphological_opening(thresholded_image, SE_size=5):\n",
        "\n",
        "    SE = np.ones((SE_size, SE_size))  # Create structuring element\n",
        "\n",
        "    # Apply erosion followed by dilation\n",
        "    opened_image = morphology.binary_dilation(\n",
        "        morphology.binary_erosion(thresholded_image, SE), SE\n",
        "    )\n",
        "\n",
        "    return opened_image"
      ],
      "metadata": {
        "id": "15Kmj8Zq1B9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mcr(opened_image):\n",
        "    # Label connected components (blobs)\n",
        "    labeled_array, num_features = measurements.label(opened_image)\n",
        "\n",
        "    # Calculate the size of each blob\n",
        "    blob_sizes = measurements.sum(opened_image, labeled_array, index=range(1, num_features + 1))\n",
        "\n",
        "    # Find the blob with the maximum size\n",
        "    max_blob_size = np.max(blob_sizes)\n",
        "    max_blob_index = np.argmax(blob_sizes) + 1  # Adjust for 0-based indexing\n",
        "\n",
        "    # Calculate the total number of pixels in the image\n",
        "    total_pixels = opened_image.size\n",
        "\n",
        "    # Calculate the MCR\n",
        "    mcr = max_blob_size / total_pixels\n",
        "\n",
        "    return mcr"
      ],
      "metadata": {
        "id": "2U4v2-lqk_j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_isolated_components(opened_image, mcr_threshold=0.8):\n",
        "    # Label connected components (blobs)\n",
        "    labeled_array, num_features = measure.label(opened_image, connectivity=2, background=0,return_num = True)  # Use 8-connectivity\n",
        "\n",
        "    # Calculate the size of each blob\n",
        "    blob_sizes = measurements.sum(opened_image, labeled_array, index=range(1, num_features + 1))\n",
        "\n",
        "    # Find the blob with the maximum size\n",
        "    max_blob_size = np.max(blob_sizes)\n",
        "    max_blob_index = np.argmax(blob_sizes) + 1  # Adjust for 0-based indexing\n",
        "\n",
        "    # Calculate the total number of pixels in the image\n",
        "    total_pixels = opened_image.size\n",
        "\n",
        "    # Calculate the MCR\n",
        "    mcr = max_blob_size / total_pixels\n",
        "\n",
        "    # Identify isolated components based on MCR\n",
        "    isolated_labels = np.where(blob_sizes / max_blob_size < mcr_threshold)[0] + 1  # Adjust for 0-based indexing\n",
        "\n",
        "    # Remove isolated components from the image\n",
        "    filtered_image = np.where(np.isin(labeled_array, isolated_labels), 0, opened_image)\n",
        "\n",
        "    return filtered_image"
      ],
      "metadata": {
        "id": "g6MVqAcFS8-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_wbc(img):\n",
        "    cmyk_img = img.convert('CMYK')\n",
        "\n",
        "    # Convert to grayscale\n",
        "    img_gray = img.convert('L')\n",
        "\n",
        "    c = cmyk_img.getchannel('C')\n",
        "    img_gray = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Otsu's thresholding method\n",
        "    thresholded_image = otsu_thresholding(img_gray)\n",
        "\n",
        "    # Remove small particles and noise\n",
        "    opening = apply_morphological_opening(thresholded_image)\n",
        "\n",
        "    # Calculates the MCR (Maximum Clump Size Ratio) of an image.\n",
        "    mcr = calculate_mcr(opening)\n",
        "    # Removes isolated components from a binary image using the maximum object algorithm and MCR.\n",
        "    filtered_image = remove_isolated_components(opening,mcr)\n",
        "\n",
        "    # Calculate the moments of the WBC with the largest center of mass\n",
        "    moments = cv2.moments(filtered_image/255)\n",
        "    x = int(moments['m10']/moments['m00'])\n",
        "    y = int(moments['m01']/moments['m00'])\n",
        "\n",
        "    # Identify the maximum WBC diameter and draw a circle around the nucleus\n",
        "    distances = np.sqrt((np.arange(filtered_image.shape[0])[:,None] - x)**2 + (np.arange(filtered_image.shape[1]) - y)**2)\n",
        "    diameter = np.max(distances[filtered_image > 0])\n",
        "    radius = np.max(distances[filtered_image > 0])/2\n",
        "    cimg = cv2.circle(np.array(img_gray), (x,y), int(radius), 255, 2)\n",
        "\n",
        "\n",
        "    # Create a bounding box around the circle\n",
        "    min_x = max(0, int(x - radius))\n",
        "    max_x = min(filtered_image.shape[1], int(x + radius))\n",
        "    min_y = max(0, int(y - radius))\n",
        "    max_y = min(filtered_image.shape[0], int(y + radius))\n",
        "\n",
        "    # Draw a rectangle (bounding box) around the circle\n",
        "    cv2.rectangle(np.array(img), (min_x, min_y), (max_x, max_y), 255, 2)\n",
        "\n",
        "    # Crop the region of interest (ROI) from the original image based on the bounding box\n",
        "    roi = np.array(img)[min_y:max_y, min_x:max_x]\n",
        "\n",
        "    return roi\n"
      ],
      "metadata": {
        "id": "N1TMOqp9cwLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory path\n",
        "directory_path = '/content/drive/MyDrive/Datasets/images/'\n",
        "\n",
        "# Get a list of file paths in the directory\n",
        "file_paths = []\n",
        "file_names = []\n",
        "for root, directories, files in os.walk(directory_path):\n",
        "    for filename in files:\n",
        "        file_path = os.path.join(root, filename)\n",
        "        image = Image.open(file_path)\n",
        "        roi = detect_wbc(image)\n",
        "        name = filename[:-4]\n",
        "        name = int(name[-3:])\n",
        "        Image.fromarray(roi).save(f'/content/drive/MyDrive/Datasets/gray_roi/{name}.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnbAMDnqvI1r",
        "outputId": "b14b0915-3719-4cb0-8df2-b277a5539336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-f1fb1d82527c>:6: DeprecationWarning: Please use `binary_dilation` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
            "  opened_image = morphology.binary_dilation(\n",
            "<ipython-input-30-f1fb1d82527c>:7: DeprecationWarning: Please use `binary_erosion` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
            "  morphology.binary_erosion(thresholded_image, SE), SE\n",
            "<ipython-input-31-36d5cc99ff52>:3: DeprecationWarning: Please use `label` from the `scipy.ndimage` namespace, the `scipy.ndimage.measurements` namespace is deprecated.\n",
            "  labeled_array, num_features = measurements.label(opened_image)\n",
            "<ipython-input-31-36d5cc99ff52>:6: DeprecationWarning: Please use `sum` from the `scipy.ndimage` namespace, the `scipy.ndimage.measurements` namespace is deprecated.\n",
            "  blob_sizes = measurements.sum(opened_image, labeled_array, index=range(1, num_features + 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train.csv\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Datasets/train.csv')\n",
        "\n",
        "# Path to the directory containing images\n",
        "image_dir = '/content/drive/MyDrive/Datasets/images/'\n",
        "\n",
        "# Preprocess images with histogram equalization\n",
        "def preprocess_images(image_names):\n",
        "    processed_images = []\n",
        "    for image_name in image_names:\n",
        "        image_path = f'{image_dir}BloodImage_{image_name:05d}.jpg'\n",
        "        image = Image.open(image_path)\n",
        "        roi = detect_wbc(image)\n",
        "        Image.SAVE(f'/content/drive/MyDrive/Datasets/c_roi/{image_name}.jpg')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NpWQpD4t0rUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CbEF737BrSnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_bajgTPqzrWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIKHs2ZdzrZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bC46T_W2zrcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FyR13nyXzre-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FABydgI0zrib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEs2KX15zrkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erbQPYNGzrnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bFhVeWL0zrqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NyVsvCwFzrt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1l-EgvH4zrw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLKuQt6Kzr0i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}